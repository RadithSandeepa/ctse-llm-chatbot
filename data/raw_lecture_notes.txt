Intro to DevOps and Beyond
Ravindu Nirmal Fernando


About Me
‚Ä¢ STL - DevOps @ Sysco LABS - Sri Lanka
‚Ä¢ MSc in Computer Science specialized in 
Cloud Computing (UOM)
‚Ä¢ AWS Certified Solutions Architect - 
Professional 
‚Ä¢ Certified Kubernetes Administrator 
(CKA)
‚Ä¢ AWS Community Builder
Ravindu Nirmal Fernando
https://ravindunfernando.com


The Era before 
DevOps


Developers
Focused on Agility
Operators
Focused on Stability


Act 01 - Operations teams 
maintaining large fragile 
applications
Doesn't have any visibility on the 
application, whether or not its 
working as expected
Act 03 - The Developers
Developers taking shortcuts and 
putting more and more fragile 
code on top of existing ones 
Act 02 - The product 
managers
Larger, unrealistic commitments 
made to the outside world (client/ 
investors) without understanding 
the complexities behind 
development and operations
Act 04 - Dev and Ops at war
"It worked on my machine" 
phenomenon 
"Destructive downward spiral in IT" - Gene Kim


How can we 
overcome 
these issues?


‚ÄúDevOps is the combination of cultural philosophies, practices, and tools 
that increases an organization‚Äôs ability to deliver applications and services 
at high velocity‚Äù
- What is DevOps? [AWS] -
‚ÄúA compound of development (Dev) and operations (Ops), DevOps is the 
union of people, process, and technology to continually provide value to 
customers.‚Äù 
- What is DevOps? [Azure] -
DevOps allows evolving and improving products at a faster pace than businesses 
using traditional software development and infrastructure management processes. 
This speed allows businesses to serve their customers better and compete effectively.


Reduce Organizational 
Silos
Everyones shares the ownership of 
production and information is 
shared among everyone
Measure Everything
Application, systems monitoring 
and metrics etc... 
Implement Gradual 
Changes
Frequent deployments, frequent 
deterministic releases in small 
chunks which can be rolled back
Accept Failure as Normal
Blameless PMs/ RCA. Risk taking 
mindset.
Leverage Tooling and 
Automation
Automate and reduce manual 
work as much as possible
Key Areas in DevOps


DevOps 
Practices


‚Ä¢ Continuous Integration (CI) - Software development practice where developers 
regularly merge their code changes into a central repository, after which automated 
builds and tests are run. 
‚Ä¢ Continuous Delivery (CD) - Software development practice where code changes are 
automatically built, tested, and prepared for a release to production (automated 
code change deployment to staging/ pre-production system). 
‚Ä¢ Continuous Deployment (CD) - Every change that passes all stages of the pipeline will 
be deployed into production (released to customers). This practice fully automates 
the whole release flow without human intervention and only a failed test will prevent a 
new change being deployed. 
‚Ä¢ Microservices - The microservices architecture is a design approach to build a single 
application as a set of small services with each focusing on SRP. Each service can be 
created, deployed and run independently.


‚Ä¢ Infrastructure as Code - A practice in which infrastructure is provisioned and 
managed using code and software development techniques, such as version control 
and continuous integration.
‚ö¨Configuration Management
‚ö¨Policy as Code
‚Ä¢ GitOps - builds on the concept of IaC, incorporating the functionality of Git 
repositories, merge requests (MRs) and CI/CD to further unify software development 
and infrastructure operations. GitOps incorporates managing both infrastructure 
and applications as code.
‚Ä¢ Cloud Infrastructure - Cloud provides more flexibility, scalability and toolsets for 
organizations to implement DevOps culture and practices. Serverless architecture in 
cloud brings down  the efforts of DevOps teams as it eliminates server management 
operations.
‚Ä¢ Continuous Monitoring, Logging and Alerting - Organizations monitor metrics and logs 
to see how application and infrastructure performance impacts the experience of 
their product‚Äôs end user. Combined with real time alerts organizations can do a real 
time analysis on the application status.


DevOps Tools 
and 
Technologies






Beyond
DevOps


"the practice of integrating security 
into a continuous integration, 
continuous delivery, and continuous 
deployment pipeline"
DevSecOps
Idea of moving Security in the 
early stages of the SDLC 
pipeline




SRE (Site Reliability Engineering)
‚ö¨Not competing with DevOps
‚ö¨Think that Class SRE implements Interface DevOps
‚ö¨SRE is a part of the DevOps umbrella
SRE Practices
- Identify and measure SLIs, define SLOs and agree/ commit to SLA for product and service
- Chaos Engineering
- Removing toil
- System designing (DR, Multi-Region, Mult-Cloud)
- Postmortems/ Root Cause Analysis
- Observability


Platform Engineering
Before jumping to definition, let‚Äôs understand the problem‚Ä¶


‚ÄúThe composition and integration of a set of processes, tools and automation 
(components) to build a coherent platform with the goal of empowering developers to 
be able to easily build, maintain and deploy their business logic‚Äù 




Carrier as a
DevOps 
Engineer


CI/ CD Management & Automation
Writing Specifications and 
Documentation
Infrastructure Management
Cloud Deployment and 
Management
Performance Assessment and 
Monitoring
DevOps Engineer Role
Assisting with DevOps culture 
apdotion 


References
‚Ä¢ https://sre.google/sre-book/table-of-contents/
‚Ä¢ https://www.gartner.com/en/articles/what-is-platform-engineering 
‚Ä¢ https://youtu.be/uTEL8Ff1Zvk?si=5QT_LrzedX-BMezt  


Thank You!
X (Twitter)
https://www.linkedin.com/in/ravindufernando/ 
LinkedIn
@ravindunf


Agenda
‚Ä¢ Brief History ‚Äì Infrastructure shifts over the 
decades
‚Ä¢ VMs vs Containers
‚Ä¢ What are containers and what problem does it 
solve?
‚Ä¢ What is Docker?
‚Ä¢ Deep dive into Docker Internals
‚Ä¢ Demo 


Brief History ‚Äì Infrastructure shifts 
over the decades
Mainframe to PC
90‚Äôs
Baremetal to Virtual
00‚Äôs
Datacenter to Cloud
10‚Äôs
Host to Container (Serverless)
Now
Let‚Äôs Recap
MAJOR INFRASTRUCTURE SHIFTS


VMS vs CONtainers
Host Operating System
Hypervisor (Type 2)
APP 1
Bins/ Libs
Host Operating System
Infrastrucutre
Infrastrucutre
Guest OS
Guest OS
Guest OS
Container Engine
APP 3
Bins/ Libs
APP 2
Bins/ Libs
APP 1
Bins/ Libs
APP 3
Bins/ Libs
APP 2
Bins/ Libs
-Virtual Machines-
-Containers-


What are containers and what problems does it solve?


Matrix from hell increases the 
complexity


Containers reduces the complexity


In summary a container is,
‚Ä¢ Just an isolated process running on the host 
machine. And a restricted process.
‚Ä¢ Will share OS and, where appropriate, bins/ 
libraries and limited to what resources it can 
access.
‚Ä¢ It exits when the process stops.
‚ÄúContainers are the next once-in-a-decade shift 
in IT infrastructure and process‚Äù 


What is docker?


‚Ä¢ So what‚Äôs Docker? ‚Äì In 2024, Docker means lot‚Äôs of things, let‚Äôs just clear things out.
‚Äì Docker as a ‚ÄúCompany‚Äù
‚Äì Docker as a ‚ÄúProduct‚Äù
‚Äì Docker as a ‚ÄúPlatform‚Äù
‚Äì Docker as a ‚ÄúCLI tool‚Äù
‚Äì Docker as a ‚ÄúComputer Program‚Äù


What is Docker?
‚Ä¢ Docker provides the ability to package and run applications within a 
loosely isolated environment which is a a container. Simply it‚Äôs a 
container engine (runtime + tool for managing containers and 
images).
‚Ä¢ It provides tooling and a platform to manage lifecycle of your 
containers,
‚Äì Develop your apps and supporting components using containers
‚Äì Distribute and test your apps as a container
‚Äì Ability to deploy your app as a container or an orchestrated service, in whatever environment which 
supports Docker installation
‚Ä¢ It shares the same OS kernel
‚Ä¢ It works on all major Linux Distributions and containers native to 
Windows Server (specific versions)


Underlying technology in docker
‚Ä¢ Docker is an extension of LXC‚Äôs (Linux Containers) 
capabilities and packaged it in a way which is 
more developer friendly.
‚Ä¢ It was developed in Go language and utilizes LXC, 
namespaces, cgroups and the linux kernel itself. 
Docker uses namespaces to provide the isolated 
workspace called a container. Each aspect of a 
container runs in a separate namespace and its 
access is limited to this namespace.




BASIC DOCKER COMMANDS


‚Ä¢ Docker CLI structure,
‚Äì Old (Still works as expected) docker <command> options
‚Äì New ‚Äì docker <command> <sub-command> (options)
‚Ä¢ Pulling Docker Image
‚Äì docker pull nginx
‚Ä¢ Running a Docker Container
‚Äì docker run ‚Äìp 80:80 --name web-server nginx
‚Ä¢ Stopping the Container
‚Äì docker stop web-server (or container id) 


‚Ä¢ Check what‚Äôs happening in a containers,
‚Äì docker container top web-server ‚Äì Process list in 1 container
‚Äì docker container inspect web-server ‚Äì Details of one container config
‚Äì docker container stats ‚Äì Performance stats for all containers
‚Ä¢ Getting a shell inside containers,
‚Äì docker container run ‚Äìit ‚Äì Start a new container interactively
‚Äì docker container exec ‚Äìit <container_id_or_name> echo ‚ÄúI‚Äôm inside the container‚Äù ‚Äì 
Run additional commands in the container
‚Ä¢ Listing, removing containers and images
‚Äì docker images
‚Äì docker container ls | docker ps 
‚Äì docker <object> rm <id_or_name>


Are there solutions other than docker?
‚Ä¢ Docker ‚Äì Container runtime + Tool for managing containers and images
‚Ä¢ Containerd ‚Äì Container runtime only
‚Ä¢ Podman ‚Äì Tool for managing containers and images


Deep dive into docker internals


Docker architecture


What happens when you run a 
container?
‚Ä¢
docker run ‚Äìp 80:80 nginx | docker container run ‚Äìp 80:80 nginx
1.
Looks for that particular image locally in image cache, if its not 
found pulls it from the configured registry (image repository). 
Downloads the latest version by default (nginx:latest)
2.
Creates a new container based on that image and prepares to 
start
3.
Docker allocates read write filesystem to the container, as its 
final layer. This allows running container to modify files and 
directories in its local filesystem.
4.
Gives it a virtual IP on a private network inside docker engine 
5.
Opens up port 80 on host and forwards to port 80 in container.
6.
Starts container by using the CMD in the image Dockerfile.


Docker Objects
‚Ä¢ Docker Images
‚Äì A read-only template with instructions/ metadata for 
creating a Docker container.
‚Äì Can create your own image or use images created and 
published in a registry by others.
‚Äì Dockerfile can be used to define steps required to 
create and run the image.
‚Äì Each instruction in Dockerfile creates a layer in the 
image, only those layers which changes each time are 
rebuilt ‚Äì What makes images so lightweight, small and 
fast.


‚Ä¢ Docker Containers
‚Äì Runnable instance of an image.
‚Äì Can create, start, stop, move, or delete a container using the Docker API or CLI.
‚Äì Can connect it to one or more networks, attach storage to it, or even create a new image based 
on its current status.
‚Äì A container is defined by its image as well as any config options provided to it when you create 
or start it. Note that when the container is removed any data associated with it will be deleted 
unless those are not stored in a persistent storage.


Understanding Docker images/ 
containers internals
‚Ä¢ Docker Filesystem
‚Äì Boot file system (bootfs) ‚Äì Contains the 
bootloader and the kernel. User never touches 
this.
‚Äì Root file system (rootfs) ‚Äì Includes the typical 
directory structure we associate with Unix-like OS.


‚Äì In traditional Linux boot, kernel first mounts the rootfs as read-only, checks its integrity, and 
then switches the rootfs volume to read-write mode.
‚Äì Docker mounts the rootfs and instead of changing the file system to read-write mode, it then 
takes advantage of union mounts service to add a read-write filesystem over the read-only file 
system. 
‚Äì In Docker terminology, a read-only layer is called an image. An image never changes and is fixed.
‚Äì Each image depend on one more image which creates the layer beneath it. The lower image is 
the parent of the upper image. Image without a parent is a base image.
‚Äì When you run a container, Docker fetches the image and its Parent Image, and repeats the 
process until it reaches the Base Image. Then the Union File System adds a read-write layer on 
top. 
‚Äì That read-write layer, plus the information about its Parent Image and some additional 
information like its unique id, networking configuration, and resource limits is called a container 




‚Äì A container can have two states, it may be running or exited. 
‚Äì When a container is exited the state of the file system and its exit value is saved. 
‚Äì You can start, stop, and restart a container. The processes of restarting a container from scratch 
will preserve its file system is just as it was when the container was stopped. But the memory 
state of the container is not preserved.
‚Äì You can also remove the container permanently. 
‚Äì A container can also be promoted directly into an image using the docker commit command. 
Once a container is committed as an image, you can use it to create other images on top of it.
‚Ä¢ docker commit <container-id> <image-name:tag>


‚Äì Based from the UFS, Docker uses a strategy called Copy 
on Write to improve the efficiency by minimizing I/O 
and the size of each subsequent layers,
‚Ä¢ If a file or directory exists in a lower layer within the image, 
and another layer (including the writable layer) needs read 
access to it, it just uses the existing file.
‚Ä¢ The first time another layer needs to modify the file (when 
building the image or running the container), the file is 
copied into that layer and modified.


‚ÄìDocker Image Creation and Storage
‚Ä¢ You can create an image using a Dockerfile or by committing a container‚Äôs 
changes back to an image.
‚Ä¢ Once you create an image, it will be stored in the Docker host‚Äôs local image 
cache.
‚Ä¢ In order to move images in/out of the local image cache,
‚ÄìExport/ Import it as a tarball
‚ÄìPush/ pull to a remote image registry (ex - DockerHub)


Docker Objects cont‚Ä¶
‚Ä¢ Docker Networks
‚Äì Each container is connected to a private virtual 
network called ‚Äúbridge‚Äù.
‚Äì Each virtual network routes through the NAT 
firewall on the host IP.
‚Äì All containers on a virtual network can talk to each 
other without exposing ports.
‚Äì Best practice is to create a new virtual network for 
each app.


‚Ä¢ Docker enables to:
‚Äì Create new virtual networks.
‚Äì Attach container to more than one virtual network (or none)
‚Äì Skip virtual networks and use host IP (--net=host)
‚Äì Use different Docker network drivers to gain new abilities. 
‚Ä¢ Docker Engine provides support for different network drivers ‚Äì bridge (default), overlay and macvian etc.. . 
You can even write your own network driver plugin to create your own one.
‚Ä¢ Docker Networking ‚Äì DNS
‚Äì Docker deamon has a built in DNS, which consider container name as equivalent hostname of 
the container.






persistence data
‚Ä¢ If we want to use persistence data as in like 
databases or unique data in containers, 
Docker enables that using two ways,
‚Äì Volumes ‚Äì Make a location outside of container 
UFS.
‚Äì Bind Mounts - Link host path to the container 
path.


Docker compose
‚Ä¢ Another Docker client, that lets you work with 
apps consisting of a set of containers.
‚Äì This saves docker container run settings in easy to 
read file, which can be committed to VCS.
‚Äì Can use this to create one-line development 
environments
‚Ä¢ Consists of two components
‚Äì YAML formatted file that describes ‚Äì Images, 
Containers, Networks, Volumes etc‚Ä¶
‚Äì A CLI tool docker-compose used to automate/manage 
those YAML files


How can we run containers at scale?


Container orchestration
‚Ä¢ Container orchestration automates the 
deployment, management, scaling, and 
networking of containers.
‚Ä¢ Container orchestration can be used in any 
environment where you use containers. It can 
help you to deploy the same application 
across different environments without 
needing to redesign it.


Introduction to docker swarm


Docker swarm key concepts
‚Ä¢ Docker Swarm provides the cluster management and orchestration features 
of Docker Engine 1.12
‚Ä¢ Nodes - A node is an instance of the Docker engine participating in the 
swarm. You can also think of this as a Docker node.
‚ÄìManager Node - To deploy your application to a swarm, you submit a 
service definition to a manager node. These nodes are also responsible for 
perform the orchestration and cluster management functions required to 
maintain the desired state of the swarm.
‚ÄìWorker Nodes - Receive and execute tasks dispatched from manager 
nodes. An agent which is running within the worker nodes report the 
current status of the tasks assigned to it which allows manager node to 
keep the desired state for each worker node.




‚Ä¢ Task - It is the atomic scheduling unit of swarm. Manager nodes assign tasks 
to worker nodes according to the number of replicas set in the service scale.
‚Ä¢ Service - the definition of the tasks to execute on the manager or worker 
nodes. Here is where you specify which container image to use and which 
commands to execute inside running containers.
‚ÄìReplicated services model - the swarm manager distributes a specific 
number of replica tasks among the nodes based upon the scale you set in 
the desired state.
‚ÄìGlobal services model - the swarm runs one task for the service on every 
available node in the cluster.
 




‚Ä¢ docker swarm init --advertise-addr <MANAGER-IP>
‚Ä¢ Join a worker node - docker swarm join --token  SWMTKN-1 
49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c 
192.168.99.100:2377
‚Ä¢ docker service create --replicas 1 --name helloworld alpine ping docker.com
‚Ä¢ docker service scale <SERVICE-ID>=<NUMBER-OF-TASKS>


Introduction to kubernetes


What is kubernetes?
‚Ä¢ ‚ÄúKubernetes (k8s) is an open source platform for 
automating deployment, scaling and 
management of containers at scale‚Äù
‚Ä¢ Project that was created by Google as an open 
source container orchestration platform. Born 
from the lessons learned and experiences in 
running projects like Borg and Omega @ Google
‚Ä¢ It was donated to CNCF (Cloud Native Computing 
Foundation) who now manages the Kubernetes 
project
‚Ä¢ Current Kubernetes stable version ‚Äì 1.29


It‚Äôs capable of‚Ä¶
‚Ä¢ Horizontal scaling
‚Ä¢ Load distribution
‚Ä¢ Service discovery
‚Ä¢ Health monitoring
‚Ä¢ Deploying new versions, rollbacks
‚Ä¢ Handling hardware faliures


High level Architecture
‚Ä¢ Master [Control Plane]  
‚Äì coordinates all activities in the cluster 
‚Ä¢ Nodes: 
‚Äì virtual or physical machines 
‚Äì actual workers 
‚Äì runs processes: 
‚Ä¢ kubelet  
‚Ä¢ kube-proxy
‚Ä¢ container runtime


Basic building blocks
‚Ä¢ Containers  
‚Äì Define single running process*  
‚Äì Eg docker container 
‚Ä¢ Pods 
‚Äì the way of running containers in kubernetes 
‚Äì basic deployable and scaling unit 
‚Äì defines one or more containers 
‚Äì containers are co-located on a node 
‚Äì flat network structure 
‚Ä¢ Nodes: 
‚Äì physical worker machines 
‚Äì can run multiple pods 
‚Äì pods running within single node don‚Äôt know about each other


      
      
              
                       
                  
   
   
             
       
    
               
         
                  
                        
       
          
       
          
   
   
   
   
                                


‚Ä¢ Minikube: 
‚Äì single node cluster 
‚Äì running in a VM 
‚Äì supports linux, windows and macOS
‚Äì mature project
Running things locally
‚Ä¢Docker Desktop with built-in 
kubernetes:
‚Ä¢ single node cluster 
‚Ä¢ running in a VM 
‚Ä¢ windows and macOS 
‚Ä¢ drag & drop installation 
‚Ä¢ bound to specific kubernetes version
‚Ä¢kind:
‚Ä¢ Requires you to have Docker or 
Podman installed in your local 
computer
https://kubernetes.io/docs/tasks/tools/ 


Managing cluster resources
‚Ä¢ Create resource from file - kubectl create -f resource_file.yml 
‚Ä¢ Change existing (or create) resource based on file - kubectl apply -f resource_file.yml 
‚Ä¢ Delete existing resource - kubectl delete resource_type resource_name 
‚Ä¢ List resources of type - kubectl get resource_type 
‚Ä¢ Edit resource on the server - kubectl edit resource_type resource_name


Debugging cluster resources
‚Ä¢ Execute command on the container - kubectl exec [-it] pod_name process_to_run
‚Ä¢ Get container logs - kubectl logs pod_name [-c container_name]
‚Ä¢ Forward port from a pod - kubectl port-forward pod_name local_port:remote_port 
‚Ä¢ Print detailed description of a resource - kubectl describe resource_type resource_name


Few resource objects in k8s
‚Ä¢ Replica Sets - Ensures desired number of pods exist by: scaling up or down and running new 
pods when nodes fail
‚Ä¢ Deployment
‚Äì A Deployment provides declarative updates for Pods and ReplicaSets. You describe a desired state in a 
Deployment, and the Deployment Controller changes the actual state to the desired state at a 
controlled rate.
‚Ä¢ Service
‚ÄìA method for exposing a network application that is running as one or 
more Pods in your cluster.
‚Ä¢ Cluster IP/ NodePort/ Load Balancer/ Ingress




demo
‚Ä¢ Defining a Pod
‚Ä¢ Creating a ReplicaSet
‚Ä¢ Creating a Deployment
‚Ä¢ Creating a Service and exposing it


Q/A


references
‚Ä¢
https://docs.docker.com/get-started/overview/
‚Ä¢
https://www.docker.com/blog/containers-and-vms-together/
‚Ä¢
https://www.redhat.com/en/topics/containers/containers-vs-vms
‚Ä¢
Docker Storage Drivers - https://docs.docker.com/storage/storagedriver/
‚Ä¢
https://docs.docker.com/storage/storagedriver/select-storage-driver/
‚Ä¢
https://www.youtube.com/watch?v=cjXI-yxqGTI
‚Ä¢
Docker Buildx - https://docs.docker.com/buildx/working-with-buildx/
‚Ä¢
Jiang Huan BuildKit timings - https://medium.com/titansoft-
engineering/docker-build-cache-sharing-on-multi-hosts-with-buildkit-and-
buildx-eb8f7005918e
‚Ä¢
What is Docker BuildKit - https://brianchristner.io/what-is-docker-buildkit/


Thank you!
LinkedIn - https://lk.linkedin.com/in/ravindufernando




KUBERNETES (K8S)
Introduction 
 Deep Dive
Ravindu Nirmal Fernando | SLIIT | February 2025
https://ravindunfernando.com 


How can we run containers at scale?


Container orchestration
‚Ä¢ Container orchestration automates the 
deployment, management, scaling, and 
networking of containers.
‚Ä¢ Container orchestration can be used in any 
environment where you use containers. It can 
help you to deploy the same application 
across different environments without 
needing to redesign it.


What is Kubernetes?
‚Ä¢ ‚ÄúKubernetes (k8s) is an open source platform for 
automating deployment, scaling and 
management of containers at scale‚Äù
‚Ä¢ Project that was created by Google as an open 
source container orchestration platform. Born 
from the lessons learned and experiences in 
running projects like Borg and Omega @ Google
‚Ä¢ It was donated to CNCF (Cloud Native Computing 
Foundation) who now manages the Kubernetes 
project
‚Ä¢ Current Kubernetes stable version ‚Äì 1.32


K8s Components & Architecture
K8s itself follows a client-
server architecture with a 
master and worker 
nodes.
<Worker Node 1>
<docker>
<Master Node>
CLI
<kubectl>
User
<docker>
<docker>
<Worker Node 2>
<Worker Node 3>


K8s Components & Architecture <cont>
API server
<kube-apiserver>
etcd
<Master Node>
CLI
<kubectl>
User
The master node has:
‚Ä¢
API server contains various methods to 
directly access the Kubernetes
‚Ä¢
etcd works as backend for service discovery 
that stores the cluster‚Äôs state and its 
configuration


K8s Components & Architecture <cont>
API server
<kube-apiserver>
etcd
controller 
manager
scheduler
<Master Node>
CLI
<kubectl>
User
‚Ä¢
Scheduler assigns to each worker node 
an application
‚Ä¢
Controller manager:
‚Ä¢
Keeps track of worker nodes
‚Ä¢
Handles node failures and 
replicates if needed
‚Ä¢
Provide endpoints to access the 
application from the outside world


K8s Components & Architecture <cont>
API server
<kube-apiserver>
etcd
controller 
manager
scheduler
<Master Node>
cloud-controller 
manager
cloud provider 
API
CLI
<kubectl>
User
‚Ä¢
Cloud controller communicates with cloud 
provide regarding resources such as nodes 
and IP addresses


K8s Components & Architecture <cont>
<Worker Node x>
kubelet
<docker>
container 1 
pod 1
container 2 
container n 
container 1 
pod 2
container 2 
container n 
API server
<kube-apiserver>
etcd
controller 
manager
scheduler
<Master Node>
cloud-controller 
manager
cloud provider 
API
CLI
<kubectl>
User
The worker node consists of:
‚Ä¢
Kubelet talks to the API server and manages 
containers on its node


K8s Components & Architecture <cont>
<Worker Node x>
kubelet
kube-proxy
<docker>
container 1 
pod 1
container 2 
container n 
container 1 
pod 2
container 2 
container n 
API server
<kube-apiserver>
etcd
controller 
manager
scheduler
<Master Node>
cloud-controller 
manager
cloud provider 
API
CLI
<kubectl>
Maggie
‚Ä¢
Kube-proxy load-balances network traffic 
between application components and the 
outside world


Basic building blocks
‚Ä¢ Containers  
‚Äì Define single running process*  
‚Äì E.g. docker container 
‚Ä¢ Pods 
‚Äì the way of running containers in Kubernetes 
‚Äì basic deployable and scaling unit 
‚Äì defines one or more containers 
‚Äì containers are co-located on a node 
‚Äì flat network structure 
‚Ä¢ Nodes: 
‚Äì physical worker machines 
‚Äì can run multiple pods 
‚Äì pods running within single node don‚Äôt know about each other


‚Ä¢ Minikube: 
‚Äì single node cluster 
‚Äì running in a VM 
‚Äì supports linux, windows and macOS
‚Äì mature project
Running things locally
‚Ä¢Docker Desktop with built-in 
kubernetes:
‚Ä¢ single node cluster 
‚Ä¢ running in a VM 
‚Ä¢ windows and macOS 
‚Ä¢ drag & drop installation 
‚Ä¢ bound to specific kubernetes version
‚Ä¢kind:
‚Ä¢ Requires you to have Docker or 
Podman installed in your local 
computer
https://kubernetes.io/docs/tasks/tools/ 


Managing cluster resources
‚Ä¢ Create resource from file - kubectl create -f resource_file.yml 
‚Ä¢ Change existing (or create) resource based on file - kubectl apply -f resource_file.yml 
‚Ä¢ Delete existing resource - kubectl delete resource_type resource_name 
‚Ä¢ List resources of type - kubectl get resource_type 
‚Ä¢ Edit resource on the server - kubectl edit resource_type resource_name


Debugging cluster resources
‚Ä¢ Execute command on the container - kubectl exec [-it] pod_name process_to_run
‚Ä¢ Get container logs - kubectl logs pod_name [-c container_name]
‚Ä¢ Forward port from a pod - kubectl port-forward pod_name local_port:remote_port 
‚Ä¢ Print detailed description of a resource - kubectl describe resource_type resource_name


Few resource objects in K8s
‚Ä¢ Replica Sets - Ensures desired number of pods exist by: scaling up or down and running new 
pods when nodes fail
‚Ä¢ Deployment
‚Äì A Deployment provides declarative updates for Pods and ReplicaSets. You describe a desired state in a 
Deployment, and the Deployment Controller changes the actual state to the desired state at a 
controlled rate.
‚Ä¢ Service
‚ÄìA method for exposing a network application that is running as one or 
more Pods in your cluster.
‚Ä¢ Cluster IP/ NodePort/ Load Balancer




Few resource objects in K8s
‚Ä¢ Ingress - An Ingress is a Kubernetes object that sits in front of multiple services and acts as 
an intelligent router. It defines how external traffic can reach the cluster services, and it 
configures a set of rules to allow inbound connections to reach the services on the cluster.


Demo
‚Ä¢ Defining a Pod
‚Ä¢ Creating a ReplicaSet
‚Ä¢ Creating a Deployment
‚Ä¢ Creating a Service and exposing it


I want to be able to 
deploy and share my 
app everywhere 
consistently, and 
manage it as a single 
entity regardless of the 
different parts.
Reference - https://github.com/IBM/helm101/tree/master 


Deploying an App ‚Äì kubectl Way
‚Ä¢ Let‚Äôs see what it takes to deploy an app on a running Kubernetes cluster
‚ÄìThere will be lot‚Äôs of YAML Kubernetes manifest files
‚Ä¢Ex:- 
‚ÄìApplication deployment and service configuration
‚ÄìRedis master deployment and service configuration
‚ÄìRedis slaves deployment and service configuration
‚ÄìUsing the Kubernetes client, kubectl
‚Ä¢Create Deployment
‚Ä¢Manage Deployment
Refer - https://github.com/IBM/guestbook/tree/master/v1 
Reference - https://github.com/IBM/helm101/tree/master 


Deploying an App ‚Äì kubectl Way ‚Äì Pain Points
‚ÄìCI/CD pipeline
‚Ä¢ kubectl deployments are not easy to configure, update and rollback 
‚Äì Deploying app to dev/test/production may require different configuration
¬ª Update deployment e.g. update with a new image
¬ª Change the configuration based on certain conditions 
¬ª A different serviceType is needed in different environments (e.g. NodePort/LoadBalancer)  
¬ª Need for rollback 
¬ª Need of having multiple deployments (e.g. multiple Redis deployments) 
‚Ä¢ Requires to track your deployment and modify YAML files (can be error prone)
‚Ä¢ Does not allow multiple deployments without updating metadata in manifest files
‚ÄìShare your deployment configurations with your friend, team or customer?
‚Ä¢ You need to share many files and related dependencies 
‚Ä¢ Your users are required to have knowledge of deployment configuration
Reference - https://github.com/IBM/helm101/tree/master 


Here Comes Helm
‚Ä¢ Deploying an app ‚Äì Helm Way 
‚Äì No expertise of Kubernetes deployment needed as Helm hides Kubernetes domain complexities 
‚Äì Helm packages all dependencies 
‚Äì Helm tracks deployment making it easy to update and rollback
‚Äì Same workload can be deployed multiple times
‚Ä¢ Helm allows assigning workload release names at runtime
‚Äì Easy to share
Reference - https://github.com/IBM/helm101/tree/master 


What is Helm?
‚ÄìHelm is a tool that streamlines installation and management of 
Kubernetes applications
‚Ä¢ A tool or package manager for the Kubernetes, for deployment and management of applications 
into a Kubernetes cluster
‚Ä¢ Helm became a CNCF project in mid 2018
‚Äì It uses a packaging format called charts
‚Ä¢ A chart is a collection of files that describe Kubernetes resources
‚Ä¢ Think of Helm like apt/yum/homebrew for Kubernetes
‚ÄìHelm is available for various operating systems like OSX, Linux and 
Windows
‚ÄìRun Helm anywhere e.g. laptop, CI/CD etc.
Reference - https://github.com/IBM/helm101/tree/master 


What Helm is NOT
‚ÄìA fully fledged system package manager
‚ÄìA configuration management tool like Chef, 
puppet etc.
‚ÄìA Kubernetes resource lifecycle controller
Reference - https://github.com/IBM/helm101/tree/master 


Reference - https://helm.sh/docs/topics/charts/ 


Demo ‚Äì Guestbook Chart Deployment
‚Ä¢
Check existing installation of Helm chart
‚Ä¢ helm ls
‚Ä¢
Check what repo do you have 
‚Ä¢ helm repo list
‚Ä¢
Add repo
‚Ä¢ helm repo add helm101 https://ibm.github.io/helm101/
‚Ä¢
Verify that helm101/guestbook is now in your repo
‚Ä¢ helm repo list
‚Ä¢ helm search helm101
‚Ä¢
Install 
‚Ä¢ helm install helm101/guestbook --name myguestbook --set service.type=NodePort ‚Äì follow the output instructions to see 
your guestbook application
‚Ä¢ Verify that your guestbook chart is installed
‚Ä¢ helm ls
‚Ä¢ Check chart release history
‚Ä¢ helm history myguestbook
Reference - https://github.com/IBM/helm101/tree/master 


Demo ‚Äì Guestbook Upgrades and Rollback
‚Ä¢ First let‚Äôs see what we have
‚Äì  helm history myguestbook
‚Ä¢ Upgrade 
‚Äì helm upgrade myguestbook helm101/guestbook
‚Äì helm history myguestbook
‚Ä¢ Rollback
‚Äì helm rollback myguestbook 1
‚Ä¢ helm history myguestbook
Reference - https://github.com/IBM/helm101/tree/master 


Demo ‚Äì Clean Up
‚Ä¢
Remove repo
‚Ä¢ helm repo remove helm101
‚Ä¢
Remove chart completely
‚Ä¢ helm delete --purge myguestbook
‚Äì Delete all Kubernetes resources generated when the chart was instantiated
Reference - https://github.com/IBM/helm101/tree/master 


Another Demo!!!
https://github.com/rav94/devops-in-practice 


References 
‚Ä¢ https://kubernetes.io/docs/concepts/overvie
w/components/ 
‚Ä¢ https://helm.sh/docs/intro/quickstart/ 




GITOPS
Introduction 
Ravindu Nirmal Fernando | SLIIT | February 2025
https://ravindunfernando.com 




GitOps in K8s
In the case of Kubernetes, GitOps deployments happen in the 
following manner:
A GitOps agent is deployed on the cluster.
‚Ä¢
The GitOps agent is monitoring one or more Git repositories that 
define applications and contain Kubernetes manifests (or Helm 
charts or Kustomize files).
‚Ä¢
Once a Git commit happens the GitOps agent is instructing the 
cluster to reach the same state as what is described in Git.
‚Ä¢
Developers, operators. and other stakeholders perform all changes 
via Git operations and never directly touch the cluster (or perform 
manual kubectl commands).


Traditional 
deployment without GitOps:
1 - A developer commits source code for the 
application.
2 - A CI system builds the application and may also 
perform additional actions such as unit tests, security 
scans, static checks, etc.
3 - The container image is stored in a Container 
registry.
4 - The CI platform (or other external system) with 
direct access to the Kubernetes cluster creates a 
deployment using a variation of the ‚Äúkubectl apply‚Äù 
command.
5 - The application is deployed on the cluster.


‚Ä¢ The cluster state is manually decided by kubectl commands or other API access.
‚Ä¢ The platform that deploys to the cluster is having full access to the Kubernetes 
cluster from an external point.


Modifying the process with GitOps
The first steps are the same. 
1 - A developer commits source code for the application and the CI system 
creates a container image that is pushed to a registry.
2 - Nobody has direct access to the Kubernetes cluster. 
3 - There is a second Git repository that has all manifests that define the 
application.
4 - Another human or an automated system changes the manifests in this 
second Git repository.
5 - A GitOps controller that is running inside the cluster is monitoring the Git 
repository and as soon as a change is made, it changes the cluster state to 
match what is described in Git.




The key points here are:
‚Ä¢ The state of the cluster is always described in Git. Git holds everything for the 
application and not just the source code.
‚Ä¢ There is no external deployment/CI system with full access to the cluster. The cluster 
itself is pulling changes and deployment information.
‚Ä¢ The GitOps controller is running in a constant loop and always matches the Git state 
with the cluster state.


Introduction to the AWS Cloud Platform
Ravindu Nirmal Fernando
2x AWS Community Builder | STL @ Sysco LABS


Agenda
‚Ä¢
Introduction to AWS cloud platform and its benefits
‚Ä¢
AWS Global Infrastructure
‚Ä¢
Accessing AWS Services
‚Ä¢
Interacting with AWS Services
‚Ä¢
Best Practices for managing AWS Accounts
‚Ä¢
Common AWS services
‚Ä¢
Demo


What is AWS Cloud?
‚Ä¢
AWS Cloud is a cloud computing platform that 
provides a wide range of services, including 
compute, storage, databases, security, 
networking, analytics, machine learning, and 
DevOps etc...
‚Ä¢
AWS Cloud is a highly scalable and reliable 
platform that can be used to build and deploy 
applications of all sizes and complexity.
‚Ä¢
AWS Cloud is also a cost-effective platform, as 
you only pay for the resources that you use.


Benefits of using AWS Cloud?
‚Ä¢
Scalability - Easily add/ remove resources as required
‚Ä¢
Reliability - Backed by reliable AWS network with proven track record of uptime and 
performance
‚Ä¢
Cost-effectiveness - Pay only for what you use
‚Ä¢
Security - Wide range of security features and services to protect your data
‚Ä¢
Innovation - 200+ fully featured services for a wide range of technologies, industries, and 
use cases
 


AWS Global Infrastructure
‚Ä¢
AWS Global infrastructure consists of a network of data centers located 
around the world. These data centers are organized into Regions and 
Availability Zones.
‚Ä¢
A Region is a geographical area that contains multiple Availability Zones. An 
Availability Zone is a logically isolated section of a Region. 
‚Ä¢
AWS Edge Locations are locations around the world where AWS content is 
cached. This allows users to access AWS content with lower latency and 
improved performance.
‚Ä¢
Regional Edge Caches are caches of frequently accessed AWS content that 
are located in close proximity to AWS customers. This allows users to access 
AWS content with even lower latency and improved performance.






Accessing AWS Services
‚Ä¢
AWS IAM (Identity and Access Management) - service that allows you to 
manage user access to your AWS resources.
‚Ä¢
IAM allows you to create Users and Groups, and assign them permissions 
policies to specific AWS resources. Users have long term credentials.
‚Ä¢
IAM Roles - Very similar to a user, in that it is an identity with permission 
policies that determine what the identity can and cannot do in AWS. But 
no credentials.
‚Ä¢
IAM Policies -  Documents that specify the permissions that are granted 
to users, groups, or roles. Used to determine what actions a user, role, or 
member of a user group can perform, on which AWS resources, and 
under what conditions. determine what actions a user, role, or member of a user group can perform, on which AWS 
resources, and under what conditions.


Interacting with AWS Services
‚Ä¢
AWS Management Console
‚Ä¢
AWS Command Line Interface
‚Ä¢
Software Development Kits
mine what actions a user, role, or member of a user group can perform, on which AWS resources, and under what conditions.


Best Practices for managing AWS Accounts
‚Ä¢
Use strong passwords, enable password policy and enable multi-factor authentication.
‚Ä¢
Create IAM users and roles and assign them permissions to specific AWS resources.
‚Ä¢
Use security groups, Network Access Controls and VPCs to protect your resources.
‚Ä¢
Implement monitoring and logging to track your AWS usage and identify potential 
problems.


Common AWS Services
‚Ä¢ Compute
‚Ä¢ Amazon Elastic Compute Cloud (EC2)
‚Ä¢ Amazon Elastic Container Service (ECS)
‚Ä¢ AWS Lambda
‚Ä¢ Storage
‚Ä¢ Amazon Simple Storage Service (S3)
‚Ä¢ Amazon Elastic Block Store (EBS)
‚Ä¢ Amazon Elastic File System (EFS)
mine what actions a user, role, or member of a user group can perform, on which AWS resources, and under what conditions.


Common AWS Services
‚Ä¢
Databases
‚Ä¢
Amazon Relational Database Service (RDS)
‚Ä¢
Amazon DynamoDB
‚Ä¢
Amazon Aurora
‚Ä¢
Networking and Content Delivery
‚Ä¢
Amazon Virtual Private Cloud (VPC)
‚Ä¢
Amazon Route 53
‚Ä¢
Amazon CloudFront


Common AWS Services
‚Ä¢ Analytics 
‚Ä¢ Amazon Redshift
‚Ä¢ Amazon Athena
‚Ä¢ Amazon Kinesis
‚Ä¢ Machine Learning
‚Ä¢ Amazon SageMaker
‚Ä¢ Amazon Rekognition
‚Ä¢ Amazon Comprehend
‚Ä¢ Amazon BedRock
mine what actions a user, role, or member of a user group can perform, on which AWS resources, and under what conditions.


Common AWS Services
‚Ä¢
DevOps
‚Ä¢
AWS CodePipeline
‚Ä¢
AWS CodeDeploy
‚Ä¢
Management & Governance
‚Ä¢
AWS CloudFormation
‚Ä¢
Amazon CloudWatch
‚Ä¢
Amazon CloudTrail
mine what actions a user, role, or member of a user group can perform, on which AWS resources, and under what conditions.


Common AWS Services
‚Ä¢
Application Integration
‚Ä¢
Amazon SNS
‚Ä¢
Amazon SQS
‚Ä¢
Amazon EventBridge
‚Ä¢
AWS Step Functions
mine what actions a user, role, or member of a user group can perform, on which AWS resources, and under what conditions.




DEMO TIME‚Ä¶


Thank You!!!


Introduction to CAP Theorem
Ravindu Nirmal Fernando  
SLIIT | March 2025
https://ravindunfernando.com 


CAP THEOREM
‚Ä¢ A fundamental theorem in distributed systems.
‚Ä¢ Can have at most two of the following three
properties,
‚Ä¢
Consistency
‚Ä¢
Availability
‚Ä¢
PartitionTolerance


DISTRIBUTED SYSTEM
üûÇConsider a simple distributed system with two servers,G1 and 
G2
üûÇThe servers can communicate with each other and connect to remote 
clients
https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/


DISTRIBUTED SYSTEM
üûÇRead example
üûÇWrite example
https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/


CONSISTENCY
Consistency means that all clients see the same data at the same time, no matter 
which node they connect to. 
For this to happen, whenever data is written to one node, it must be instantly 
forwarded or replicated to all the other nodes in the system before the write is 
deemed ‚Äòsuccessful.‚Äô


CONSISTENCY
Inconsistent system
https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/


CONSISTENCY
Consistent system
https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/


AVAILABILTY
Availability means that any client making a request for data gets a response, even if 
one or more nodes are down. 
Another way to state this‚Äîall working nodes in the distributed system return a 
valid response for any request, without exception.


PARTITION TOLERANCE
A partition is a communications break within a distributed system‚Äîa lost or 
temporarily delayed connection between two nodes. 
Partition tolerance means that the cluster must continue to work despite any 
number of communication breakdowns between nodes in the system.


PARTITION TOLERANCE
The system continues to operate despite network partitions
‚Ä¢
Communication among the servers is not reliable
‚Ä¢
Servers may be partitioned into multiple groups that
cannot communicate with each other
‚Ä¢
Messages may be delayed or lost forever
https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/


PROOF
Consider partitioned system,
https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/


PROOF
Client writes to G1
https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/


PROOF
Client reads from G2
https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/
NOT CONSISTENT!


PROOF
Client reads from G2
https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/
NOT AVAILABLE!


SYSTEM DESIGN
This suggests there are three kinds of distributed systems
‚Ä¢
CP
‚Ä¢
CA
‚Ä¢
AP
Why is it important?
‚Ä¢
Future of databases is distributed (Big DataTrend)
‚Ä¢
CAP theorem describes the trade-offs involved in
distributed systems
‚Ä¢
Proper understanding of CAP theorem is essential to
making decisions about distributed database/system design
‚Ä¢
Misunderstanding can lead to erroneous or inappropriate
design choices


CONSISTENCY OR AVAILABILITY
‚Ä¢ Consistency &Availability is not‚Äúbinary‚Äù decision
‚Ä¢ AP systems relax consistency in favor of availability ‚Äì but
are not inconsistent
‚Ä¢ CP systems sacrifice availability for consistency- but are
not unavailable
‚Ä¢ This suggests both AP & CP systems can offer a degree
of consistency,& availability,as well as partition tolerance


CONSISTENCY MODELS
Strong Consistency
‚Ä¢
After the update completes,any subsequent access will return the
same updated value.
Weak Consistency
‚Ä¢
It is not guaranteed that subsequent accesses will return the
updated value.
Eventual Consistency
‚Ä¢
Specific form of weak consistency
‚Ä¢
It is guaranteed that if no new updates are made to object,eventually
all accesses will return the last updated value (e.g.,propagate updates
to replicas in a lazy fashion)


EVENTUAL CONSISTENCY ‚Äì FACEBOOK EXAMPLE
‚Ä¢ Bob finds an interesting story and shares with Alice by 
posting on her Facebook wall
‚Ä¢ Bob asksAlice to check it out
‚Ä¢ Alice logs in her account,checks her Facebook wall but
- Nothing is there!


EVENTUAL CONSISTENCY ‚Äì FACEBOOK EXAMPLE
‚Ä¢ Bob tells Alice to wait a bit and check out later
‚Ä¢ Alice waits for a minute or so and checks back ‚Äì Finds the
wall post!


EVENTUAL CONSISTENCY ‚Äì FACEBOOK EXAMPLE
‚Ä¢ Why would Facebook choose an eventual consistent
model over the strong consistent one?
‚Ä¢
Facebook has billions of active users
‚Ä¢
It is non-trivial to efficiently and reliably store the huge amount
of data generated at any given time
‚Ä¢
Eventual consistent model offers the option to reduce the load
and improve availability


DYNAMIC TRADEOFF BETWEEN C AND A
An airline reservation system:
‚Ä¢
When most of seats are available:it is ok to rely on
somewhat out-of-date data,availability is more critical
‚Ä¢
When the plane is close to be filled:it needs more
accurate data to ensure the plane is not overbooked,
consistency is more critical
Neither strong consistency nor guaranteed availability,but it 
may significantly increase the tolerance of network 
disruption


REFERENCES
‚Ä¢
Gilbert,Seth,andNancy Lynch."Perspectives on theCAP Theorem."
Computer 45.2(2012):30-36
‚Ä¢
https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_t
heorem/ 
‚Ä¢
theorem #:~ :text= T he% 20C A P % 20theorem
% 20s a ys % 20tha t,'P '% 20in% 20C A P
 


Key Essesntials for Building Apps 
in Cloud
Ravindu Nirmal Fernando  
SLIIT | March 2025
https://ravindunfernando.com 


Shared Responsibility Model in Public 
Cloud
‚Ä¢
A framework that outlines how security responsibilities are divided 
between the cloud service provider and the cloud user. 
‚Ä¢
Security and compliance is a shared responsibility between AWS 
and the customer. Cloud service provider manages the 
infrastructure, while customers are responsible for managing their 
data and applications.
‚Ä¢
Cloud Service Provider (CSP) Responsibility: Known as "Security of 
the Cloud." CSP is in charge of the infrastructure, including 
hardware, software, networking, and physical security.
‚Ä¢
Customer Responsibility: Termed "Security in the Cloud." 
Customers handle the guest operating system, application software, 
and AWS-provided firewall configuration.


Key aspects of Shared Responsibility 
Model
‚Ä¢ Service/ Delivery Models: Responsibilities 
vary depending on whether the service is IaaS 
(like EC2), PaaS, or SaaS.
‚Ä¢ IT Controls: Shared management of IT controls 
between CSP and customers. CSP manages 
physical infrastructure controls, while 
customers handle specific application-level 
controls.


Control types in Shared Responsibility 
Model
‚Ä¢
Inherited Controls: Controls fully managed by CSP (e.g., physical 
and environmental controls).
‚Ä¢
Shared Controls: Controls that apply to both CSP and customers but 
in different contexts (e.g., patch management, configuration 
management).
‚Äì Patch Management ‚Äì CSP is responsible for patching and fixing flaws 
within the infrastructure, but customers are responsible for patching 
their guest OS and applications.
‚Äì Configuration Management ‚Äì CSP maintains the configuration of its 
infrastructure devices, but a customer is responsible for configuring 
their own guest operating systems, databases, and applications.
‚Äì Awareness & Training - CSP trains CSP‚Äôs employees, but a customer 
must train their own employees.
‚Ä¢
Customer Specific Controls: Controls solely managed by the 
customer, depending on their applications and use of CSP services.




How to use Shared Responsibility 
Model practically‚Ä¶
‚Ä¢ Understanding the Model: Customers need to comprehend 
the CSP Shared Responsibility Model and its general 
application in cloud operations.
‚Ä¢ Application to Use Case: Determine the model's relevance 
to their specific use case.
‚Ä¢ Variability in Responsibility: Customer responsibility 
changes based on:
‚Äì The choice of CSP services and geographical locations. (e.g: AWS 
EC2 in specified AWS region)
‚Äì How these services integrate into their IT environment.
‚Ä¢ Legal and Regulatory Considerations: Consideration of laws 
and regulations that apply to their organization and 
workload.


Reference: Above the Clouds: A Berkeley View of Cloud Computing, 2009.
Resource Provisioning


Scalability in Cloud
‚Ä¢ Horizontal scaling
‚Äì The allocating or releasing of IT resources that are of the same type
‚Äì Scaling in and out


‚Ä¢ Vertical scaling
‚Äì Existing IT resource is replaced by another with higher or lower capacity
‚Äì Scaling up & down


Horizontal vs Vertical Scaling
Aspect
Horizontal Scaling (Scaling Out/In)
Vertical Scaling (Scaling Up/Down)
Definition
Adding or removing servers to adjust capacity.
Increasing or decreasing the capacity of a server.
Cost
Can be more cost-effective with pay-as-you-go 
models.
May involve higher costs due to high-end hardware.
Downtime
Often allows scaling with no downtime.
May require downtime for hardware upgrades.
Resource Limits
Limited by the number of servers you can add.
Limited by the maximum capacity of a single server.
Complexity
Can increase architectural complexity.
Simpler, as it involves a single resource.
Availability
Improved, as load is distributed across multiple 
servers.
Risk of a single point of failure.
Use Case
Ideal for distributed systems and microservices.
Suited for applications with fixed or known peaks.


‚Ä¢ Reactive scaling
‚Äì Once something (e.g., workload) happen
‚Ä¢ Proactive scaling
‚Äì Based on predictions (e.g., workload)
Based on
‚Ä¢ Rules
‚Äì Spawn a new VM if ave. CPU util. > 80%
‚Ä¢ Models based on QoS/SLA targets
‚Äì No of VMs to maintain latency < 300 ms


Cloud Security Basics and Countermeasures
Based on Cloud Computing: Concepts, Technology Architecture, Thomas Erl, et al., Prentice-Hall, 2013,


Concepts
Confidentiality
‚Ä¢
Accessible only to authorized parties
‚Ä¢
Within cloud environments, confidentiality targets to restricting access to
data in transit and storage.


Concepts
Integrity
‚Ä¢
Not having been altered by an unauthorized party
‚Ä¢
Can cloud consumer be guaranteed transmitted data to matches the data
received.
‚Ä¢
Extends to how data is stored, processed, and retrieved.


Concepts
Authenticity
‚Ä¢
Ensuring something has been provided by an authorized source.
‚Ä¢
Can cloud consumer guarantee the authentication of an interaction and no 
other party can deny or challenge that.
Availability
‚Ä¢
Being accessible, available and usable within defined time period.
‚Ä¢
In cloud the availability of cloud services can be a responsibility that is shared 
by the cloud provider and the cloud carrier. The availability of a cloud-based 
solution that extends to cloud service consumers is further shared by the 
cloud consumer.


Threat Agents
An entity that poses a threat because it is capable of carrying out an
attack.
‚Ä¢
Can originate either internally or externally.
‚Ä¢
Human or Software.


Threat Agents


Threat Agents
Anonymous Attacker
‚Ä¢
Non-trusted cloud service consumer without permissions in the cloud. Attempts attacks 
from outside cloud permission boundary, mostly using public networks.
Malicious Service Agent
‚Ä¢
Able to intercept and forward the network traffic that flows within a cloud. Then to 
maliciously use and augment the data.
Trusted Attacker
‚Ä¢
Shares IT resources in the same cloud environment as the cloud consumer and attempts
to exploit legitimate credentials to target cloud providers and the cloud tenants.
Malicious Insider
‚Ä¢
Human threat agents acting on behalf of or in relation to the cloud provider. Typically
current or former employees or third parties with access to the cloud provider‚Äôs premises.


Cloud Security Threats
‚Ä¢
Traffic Eavesdropping
‚Ä¢
Malicious Intermediary
‚Ä¢
Denial of Service
‚Ä¢
Insufficient Authorization
‚Ä¢
Virtualization Attack
‚Ä¢
Overlapping Trust Boundaries


Traffic Eavesdropping
Data transferred to or within a cloud is passively intercepted by a malicious service agent for
information gathering purposes.
‚Äì
Aim to compromise the confidentiality of the data.
‚Äì
Due to passive nature of the attack, it can take place undetected for extended periods
of time.


Malicious Intermediary
Messages are intercepted and altered by a malicious service agent.
‚Ä¢
Potentially compromising the m    g ‚Äô confidentiality and/or integrity.
‚Ä¢
May insert harmful data into the message.


Denial of Service
Overload IT resources to the point where they cannot function properly.
‚Ä¢
The workload on cloud services is artificially increased with imitation messages or
repeated communication requests.
‚Ä¢
The network is overloaded with traffic to reduce its responsiveness and
cripple its performance.
‚Ä¢
Multiple cloud service requests are sent, each of which is designed 
to consume
excessive memory and processing resources.


Denial of Service


Insufficient Authorization
Occurs when access is granted to an attacker erroneously or too broadly
to IT resources that are normally protected.
‚Ä¢
Result of the attacker gaining direct access to IT resources that were implemented to
be accessed by trusted consumer programs.


Virtualization Attack
Exploits vulnerabilities in the virtualization platform to jeopardize its
confidentiality, integrity, and/or availability.


Overlapping Trust Boundaries
Target shared IT resources with the intention of compromising cloud 
consumers or other IT resources that share the same trust boundary


Checklist on Cloud Security
Substandard design, implementation or configuration
‚Ä¢
Security issues may arise beyond runtime exception or system failures
‚Ä¢
Attackers may exploit these vulnerabilities


Checklist on Cloud Security (Cont)
Security policy checks
‚Ä¢
Check for any disparity as majority of the IT resources are now managed by cloud
service providers
Contracts
‚Ä¢
Examine contracts and SLAs put forth by cloud providers to ensure that security
policies, and other relevant guarantees, are satisfactory when it comes to security
Risk Management
‚Ä¢
Continuous risk assessment as part of risk management strategy


Cloud Security Countermeasures
Encryption
Secret key based encryption mechanisms to counter traffic 
eavesdropping, malicious intermediary, insufficient authorization, and 
overlapping trust boundaries security threats.


Encryption
Symmetric Encryption
‚Ä¢
Secret key cryptography, uses the same key for both encryption and decryption
‚Ä¢
Does not have the characteristic of non-repudiation, cannot determining which party
performed the message encryption or decryption
Asymmetric Encryption
‚Ä¢
Relies on the use of two different keys, private key and a public key
‚Ä¢
private key is known only to its owner while the public key is commonly available
‚Ä¢
D    ‚Äô provide message integrity or authenticity protection due to the communal
nature of the public key


Hashing
When non-reversible form of data protection is required
‚Ä¢
Derive a hashing code or message digest from a message
‚Ä¢
Sender attach message digest to the message
‚Ä¢
Recipient applies the same hash function to the message to verify that the produced
message digest is identical to the one that accompanied the message


Digital Signature
Messages are assigned a digital signature prior to transmission, which is then
rendered invalid if the message experiences any unauthorized modifications
‚Ä¢
Both hashing and asymmetrical encryption are involved in the creation of a digital
signature


Public Key Infrastructure (PKI)
‚Ä¢
Used to associate public keys with their corresponding key owners
‚Ä¢
Rely on the use of digital certificates, which are digitally signed data
structures that bind public keys to certificate owner identities with a validity
time period
‚Ä¢
Digital certificates are usually digitally signed by a third- party certificate
authority


Public 
Key
Private 
Key
Can be 
distributed to 
anyone
Will be always 
private
Request 
Sends her public key to encrypt the message 
Encrypts and sends the Secure message 
Public 
Key
Private 
Key
DECRYPTION




Identity Access Management (IAM)
‚Ä¢
IAM encompasses controlling and tracking user identities and 
access in IT environments.
‚Ä¢
Authentication: Manages credentials like usernames, passwords, 
digital signatures, biometric data, and binds accounts to specific 
hardware or software identifiers.
‚Ä¢
Authorization: Defines access control levels and manages 
relationships between user identities, access rights, and resource 
availability.
‚Ä¢
User Management: Involves administrative tasks like creating user 
accounts, resetting passwords, setting password policies, and 
managing privileges.
‚Ä¢
Credential Management: Establishes and manages access rules for 
user accounts to prevent unauthorized access.


Single Sign-On (SSO)
Propagating the authentication information
across multiple cloud services can be a
challenging
‚Ä¢
Enables authentication by a security broker
that establish a persisted security context
during consumer accesses to cloud services


Single Sign-On (SSO)


Cloud-Based Security Groups
‚Ä¢
Cloud resource segmentation is a
process by which separate physical 
and virtual IT environments are
created for different users and
groups


Hardened Virtual Server Images
Process of stripping unnecessary software to limit potential vulnerabilities that
can be exploited by attackers
‚Ä¢
Removing redundant programs, closing unnecessary server ports, and disabling
unused services, internal root accounts, and guest access


References
‚Ä¢ https://aws.amazon.com/compliance/shared-
responsibility-model/
‚Ä¢ Chapter 6 and 10, Cloud Computing: 
Concepts, Technology & Architecture, Thomas 
Erl, et al., Prentice- Hall, 2013


Introduction to Microservices
Ravindu Nirmal Fernando  
SLIIT | March 2025
https://ravindunfernando.com 


Foundations of Modern Software 
Architecture: Paving the Way for 
Microservices
‚Ä¢
Influential Concepts and Technologies
‚Äì
Domain-Driven Design: Emphasizing the importance of reflecting real-world 
complexities in our code for better system modeling.
‚Äì
Continuous Delivery: Revolutionizing software deployment, making every code check-in 
a potential release candidate.
‚Äì
Web Communication Advancements: Enhancing how machines interact, leading to 
more efficient and robust systems.
‚Ä¢
Architectural Shifts
‚Äì
From Layered to Hexagonal: Moving away from traditional layered architectures to 
avoid hidden complexities in business logic.
‚Äì
Embracing Virtualization: Utilizing on-demand provisioning and resizing of resources for 
greater flexibility with cloud computing.
‚Ä¢
Organizational Practices
‚Äì
Small Autonomous Teams: Inspired by tech giants like Amazon and Google, promoting 
ownership and lifecycle management of services.
‚Äì
Learning from Netflix: Building resilient, scalable systems that can withstand and adapt 
to change.


Microservices: A Natural Progression
‚Ä¢ Emergence from Real-World Use: 
Microservices weren‚Äôt pre-planned but 
evolved as a response to practical needs in 
software development.
‚Ä¢ Responding to Change: Offering the agility and 
flexibility to adapt to new technologies and 
market demands.


Monolithic Applications
‚Ä¢
Basic Structure
‚Äì Single-Tiered Structure: Built as a single, unified unit.
‚Äì Combined Modules: Functional modules like UI, server logic, and database 
interactions are combined.
‚Ä¢
Design and Construction
‚Äì Modular Architecture: Follows a modular structure within a single unit, 
aligning with object-oriented principles.
‚Äì Programming Constructs: Defined using language-specific constructs (e.g., 
Java packages).
‚Äì Build Artifacts: Built as a single artifact, such as a Java JAR file.
‚Ä¢
Characteristics
‚Äì Inter-module Dependencies: Modules are tightly coupled and interdependent.
‚Äì Unified Deployment: Deployed as a single entity.
‚Ä¢
Scalability
‚Äì Scalability Approach: Scaling involves replicating the entire application, not 
individual components.


Diagram of a monolithic ecommerce application with several modules using a combination of 
programming language constructs. (https://cloud.google.com/architecture/microservices-architecture-
introduction)


‚Ä¢ Benefits of Monolithic Architecture
‚Äì Simplified Testing: Tools like Selenium enable end-to-end testing of the entire application.
‚Äì Ease of Deployment: Deployment involves simply copying the packaged application to a server.
‚Äì Resource Sharing: All modules share memory, space, and resources, streamlining cross-cutting 
concerns like logging, caching, and security.
‚Äì Intra-Process Communication: Direct module-to-module calls can offer performance advantages over 
network-dependent microservices.
‚Ä¢ Challenges of Monolithic Architecture
‚Äì Scalability Issues: Difficulty in scaling when different modules have conflicting resource requirements.
‚Äì Complexity in Maintenance and Updates: As the application grows, implementing changes becomes 
more complicated due to tightly coupled modules.
‚Äì CI/CD Complications: Continuous integration and deployment become challenging as any update 
requires redeploying the entire application.
‚Äì Vulnerability to System Failures: A bug in any module, like a memory leak, can crash the entire system.
‚Äì Technological Rigidity: Adopting new frameworks or languages is costly and time-consuming, as it 
often requires rewriting the entire application.


Understanding Microservices 
‚Ä¢ Core Characteristics
‚Äì Small and Focused: Aimed at doing one thing well, 
avoiding sprawling codebases.
‚Äì Cohesion and Single Responsibility: Adhering to the 
principle of grouping related code and separating 
unrelated functionalities.
‚Ä¢ Size and Scope
‚Äì No Fixed Size: Size varies based on language 
expressiveness and domain complexity.
‚Äì Team Alignment: Ideally sized to be managed by a small 
team.
‚Äì Balance in Size: Smaller services maximize benefits but 
increase complexity.


‚Ä¢ Autonomy
‚Äì Independent Entities: Deployed separately, can be different technologies, possibly as isolated services 
on a PAAS or as individual operating system processes.
‚Äì Network Communication: Services communicate via network calls, ensuring separation and reducing 
tight coupling.
‚Ä¢ Deployment and Change Management
‚Äì Independent Deployment: Services can be deployed independently without impacting others.
‚Äì API-Centric Interaction: Services expose APIs for interaction, emphasizing decoupled, technology-
agnostic interfaces.
‚Ä¢ Decoupling
‚Äì Key to Microservices: Essential for maintaining independence and achieving the benefits of 
microservices architecture.
‚Äì Change and Deployment: Ability to change and deploy a service independently is crucial.


Diagram of an ecommerce application with functional areas implemented by microservices. 
(https://cloud.google.com/architecture/microservices-architecture-introduction)


‚Ä¢ Database Relationship
‚Äì Service-Specific Databases: Each microservice has its own database tailored to its requirements.
‚Äì Loose Coupling: This approach ensures loose coupling by routing data requests through service APIs 
instead of a shared database.
‚Äì Independent Data Management: Each service manages its data independently, enhancing autonomy 
and reducing interdependencies.


Benefits of Microservices Architecture
Aspect
Benefit Details
Enhanced Development and Maintenance
- Breaks application into smaller, manageable chunks.
- Clear boundaries with defined APIs.
- Quicker development, easier understanding and maintenance.
Team Autonomy and Efficiency
- Independent development of services by teams.
- Full lifecycle ownership of services.
- Flexibility to use different programming languages (Polyglot Development).
Improved Scalability and Market 
Responsiveness
- Independent scaling based on service needs.
- Hardware optimization for resource requirements.
- Faster product delivery and improved time to market.


Challenges of Microservices 
Architecture
Challenge Category
Challenge Details
Complexity in Distributed Systems
- Necessity of choosing and implementing inter-service communication mechanisms.
- Managing partial failures and service unavailability.
Transaction Management Across 
Services
- Handling atomic operations across multiple microservices (Distributed Transactions).
- Maintaining data consistency during failures (Consistency Issues).
Testing and Deployment Complexities
- Requirement for comprehensive testing across multiple services.
- Complexities in managing multiple service deployments and service discovery.
Operational Overhead
- Increased need for monitoring and alerting across more services.
- Higher risk of failure due to more points of service-to-service communication.
- Challenges in productionizing and maintaining robust operations infrastructure.
Performance and Suitability 
Considerations
- Potential latency issues due to network calls between services.
- Not suitable for all types of applications, especially those requiring real-time data processing.
- Importance of clear communication and service boundary planning.


Migrating from Monolithic to 
Microservices: Key Considerations
Consideration Category
Details
Assessing the Need for Migration
- Evaluate if microservices align with business goals and pain points.
- Consider simpler alternatives like autoscaling or enhanced testing.
Starting the Migration Process
- Begin with extracting and deploying one service independently.
- Adopt an iterative approach, learning and adapting with each service migration.
Strategic Implementation
- Recognize varying approaches to microservice size and quantity among teams.
- Emphasize continuous learning and strategy refinement.
Future Learning and Strategies
- Explore strategies for detailed refactoring from monolithic to microservices.
- Plan for ongoing education and adaptation of methods.


References
‚Ä¢ https://cloud.google.com/architecture/micros
ervices-architecture-introduction 
‚Ä¢ Building Microservices, Sam Newman


Microservice 
Design Patterns
Ravindu Nirmal Fernando  
SLIIT | March 2025
https://ravindunfernando.com 


Design Patterns for migrating 
Monoliths to Microservices
‚Ä¢ Anti-Corruption Layer (ACL) pattern
‚Ä¢ Strangler fig pattern


Anti-Corruption Layer (ACL) pattern
‚Ä¢ Allows gradual translation from monoliths to 
microservices architecture. 
‚Ä¢ Allows legacy systems to communicate with modern 
services without internal changes and with minimal 
impact.
‚Ä¢ Goal of ACLs is to minimize changes to existing 
functionality in monoliths and reduce business 
disruptions. 
‚Ä¢ Acts as an adapter or facade, converting calls to the 
new interface.
‚Ä¢ ACL is also consumed as a part of Strangler-Fig pattern 
which we are going to talk next‚Ä¶


Existing Monolithic App
Introduction of ACL layer when User service is migrated




Strangler fig Pattern
‚Ä¢ Helps migrating a monolithic application to a 
microservices architecture incrementally, with reduced 
transformation risk and business disruption.
‚Ä¢ Migrating a monolithic application to microservices 
based one requires rewriting and refactoring the code 
base and doing it once will be a huge risk.
‚Ä¢ Hence Strangler fig patterns allows teams to focus on 
doing this migration incrementally and gradually while 
allowing app users to use the newly migrated features 
progressively. 


Process Involved in Strangler fig
‚Ä¢ Identify Replaceable Components: Start with 
parts of the system that are easiest to replace 
or most in need of an upgrade.
‚Ä¢ Build New Features as Services: Develop new 
functionalities as separate services outside the 
legacy system.
‚Ä¢ Reroute Traffic: Gradually reroute user traffic 
from the old system to the new services.


A monolithic application has three services: user service, cart service, 
and account service. The cart service depends on the user service, and 
the application uses a monolithic relational database.
https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/strangler-fig.html 


First step is to add a proxy layer between the storefront UI and the 
monolithic application. At the start, the proxy routes all traffic to the 
monolithic application.
https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/strangler-fig.html 


New services are implemented as microservices instead of adding 
features to the existing monolith. However, you continue to fix bugs in 
the monolith to ensure application stability. The proxy layer routes the 
calls to the monolith or to the new microservice based on the API URL.
https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/strangler-fig.html 


During the migration process, when the features within the monolith 
need to call the features that were migrated as microservices, the ACL 
converts the calls to the new interface and routes them to the 
appropriate microservice.
https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/strangler-fig.html 


Data synchronization is crucial when downstream services, rely on a monolithic architecture, use 
data from a microservice. In this scenario, a User microservice, which has its own data layer, 
requires synchronization with the monolith. To facilitate this, a synchronization agent can be 
introduced. Update events from the microservice's database are sent to a queue. The agent then 
reads these events from the queue and synchronizes them with the monolithic database, ensuring 
eventual data consistency between the microservice and the monolith.
https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/strangler-fig.html 


Once all interdependent components have been fully migrated to 
microservices, it becomes feasible to refactor the code to eliminate 
the Anti-Corruption Layer (ACL) components.
https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/strangler-fig.html 


The final strangled state where all services have been migrated out of 
the monolith and only the skeleton of the monolith remains. Historical 
data can be migrated to data stores owned by individual services. The 
ACL can be removed, and the monolith is ready to be decommissioned 
at this stage.
https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/strangler-fig.html 


The final architecture after the monolithic application has been 
decommissioned.
https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/strangler-fig.html 


Microservice Design Patterns
In a distributed transaction, multiple services can be called before a 
transaction is completed. When the services store data in different 
data stores, it can be challenging to maintain data consistency 
across these data stores.
Saga Pattern - A saga consists of a sequence of local transactions. Each 
local transaction in a saga updates the database and triggers the next local 
transaction. If a transaction fails, the saga runs compensating transactions 
to revert the database changes made by the previous transactions.
‚Ä¢
Manages Distributed Transactions Across Multiple Microservices and Databases.
‚Ä¢
Breaks Down a Transaction into a Series of Local Transactions for Each Service.
‚Ä¢
Addresses the challenge of maintaining atomicity, consistency, isolation, and durability in 
microservices. 
‚Ä¢
Utilizes Compensating Transactions or Actions in Case of Local Transaction Failures.
‚Ä¢
Avoids Using Two-Phase Commit Protocols for Transaction Management.
‚Ä¢
Maintains Overall System Consistency Through Compensatory Mechanisms.


Saga Choreography
‚Ä¢ Ensures data integrity in distributed 
transactions across multiple services using 
event subscriptions.
‚Ä¢ Depends on the events published by the 
microservices.
‚Ä¢ The saga participants (microservices) 
subscribe to the events and act based on the 
event triggers.


https://docs.aws.amazon.com/prescriptive-guidance/latest/cloud-design-patterns/saga-choreography.html#saga-choreography-implementation 


Use the saga choreography pattern when:
‚Ä¢ Your system requires data integrity and consistency in distributed transactions that span multiple data stores.
‚Ä¢ The data store (for example, a NoSQL database) doesn't provide 2PC to provide ACID transactions, you need 
to update multiple tables within a single transaction, and implementing 2PC within the application boundaries 
would be a complex task.
‚Ä¢ A central controlling process that manages the participant transactions might become a single point of 
failure.
‚Ä¢ When there are small number of participants (microservices) involved.
‚Ä¢ The saga participants are independent services and need to be loosely coupled.
‚Ä¢ There is communication between bounded contexts in a business domain.


Saga Orchestrator
‚Ä¢ Uses a central coordinator (orchestrator) to help 
preserve data integrity in distributed transactions that 
span multiple services.
‚Ä¢ Utilizes the orchestrator to manage the transaction 
lifecycle. Orchestrator is aware of all the steps required 
for transaction.
‚Ä¢ Orchestrator sends messages to to participant 
microservices to initiate operations. These participant 
microservices report back to the orchestrator.
‚Ä¢ Orchestrator acts as the decision maker and 
determines the next microservice to engage based on 
received messages. 




Use the saga orchestration pattern when:
‚Ä¢ Your system requires data integrity and consistency in distributed transactions that span multiple data stores.
‚Ä¢ The data store doesn't provide 2PC to provide ACID transactions, and implementing 2PC within the application 
boundaries is a complex task.
‚Ä¢ You have NoSQL databases, which do not provide ACID transactions, and you need to update multiple tables 
within a single transaction.
‚Ä¢ Your system has many saga participants (microservices) involved and loose coupling between participants are 
required.


Developing and deploying 
Microservices with K8s
‚Ä¢
Traffic Management with Ingress:
‚Äì
Using Kubernetes Ingress for efficient HTTP/HTTPS routing to services.
‚Äì
Ingress acts as a reverse proxy, simplifying routing and providing SSL/TLS termination and load 
balancing.
‚Ä¢
Scaling Microservices:
‚Äì
Leveraging tools like Horizontal Pod Autoscaler (HPA) for automatic scaling based on CPU 
usage or custom metrics.
‚Äì
Kubernetes also supports manual scaling for handling varying loads effectively.
‚Ä¢
Using Namespaces for Organization:
‚Äì
Utilizing Kubernetes namespaces to divide cluster resources among multiple users or teams.
‚Äì
Grouping related services in the same namespace simplifies management and applies policies 
at the namespace level.
‚Ä¢
Implementing Health Checks:
‚Äì
Essential for monitoring the status of services using readiness and liveness probes.
‚Äì
Health checks allow Kubernetes to replace non-functioning pods automatically.
‚Ä¢
Service Mesh for Advanced Traffic Management:
‚Äì
Implementing a service mesh for handling service-to-service communication.
‚Äì
Provides traffic management, service discovery, load balancing, and failure recovery.


‚Ä¢
Single Responsibility Principle for Microservices:
‚Äì Design each microservice with a single responsibility for easier scaling, 
monitoring, and management.
‚Äì Tailor scaling policies, resource quotas, and security configurations to 
the specific needs of each service.
‚Ä¢
Continuous Delivery/Deployment (CD):
‚Äì Utilizing Kubernetes Deployment objects for a declarative 
management of microservices.
‚Äì Implement rolling updates for gradual change rollout and use tools like 
Argo Rollouts for more reliable rollback and progressive deployment 
strategies.
‚Ä¢
Monitoring and Debugging:
‚Äì Collect and visualize metrics using tools like Prometheus and Grafana.
‚Äì Use application performance monitoring (APM) tools for detailed 
performance data of microservices.


References
‚Ä¢ https://docs.aws.amazon.com/prescriptive-
guidance/latest/cloud-design-
patterns/introduction.html 
‚Ä¢ https://learn.microsoft.com/en-
us/azure/architecture/patterns/ 




Design Patterns 
A generally reusable solution to a recurring 
problem 
 
 
A template to solve the problem 
Best practices in approaching the problem 
Improve developer communication 


Cloud Application Development Issues 
Availability 
‚Ä¢ The guaranteed proportion of time that the system 
is functional 
SLA ‚Äì Service Level Agreement 
Availability (%) 
Downtime per year 
99.999
99.95
5 minutes
1 hour
99.99
99.9
99
4.4 hours
9 hours
3.7 days


Cloud Application Development Issues 
 
Design and Implementation 
 
 
Consistent and coherent component design 
Improves ease of deployment and maintenance 
Reusability of components 
Typically hosted in different locations and across 
multiple servers for performance, scalability and 
availability 
Maintaining consistency and synchronizing 
Data Management
 
 


Cloud Application Development Issues 
Design and Implementation 
 
 
Messaging infrastructure to connect distributed 
components and services 
Asynchronous messaging 
Consistent and coherent component design 
Improves ease of deployment and maintenance 
Reusability of components 
Messaging


Cloud Application Development Issues 
Performance and Scalability 
Cloud applications run in in a remote servers with 
limited control 
Responsiveness of a system to execute any action 
within a given time interval 
Handle increases in load without impact on 
performance 
How to handle variable workloads? 
Management and Monitoring


Cloud Application Development Issues 
Security 
Resiliency 
Ability of the application to gracefully handle and 
recover from failures 
Applications are more prone to failure in cloud 
environments 
Prevent malicious or accidental actions outside of the 
designed usage 
Prevent disclosure or loss of information 


High-Level Model 
STS ‚Äì Security Token Service 
IDP ‚Äì Identity Provider 


Cache-Aside Pattern 
Solutions 
Load on demand data into a 
cache from a data store 
Pros 
Increased performance 
Cons 
 
 
 
Azure Cache AWS ElastiCache 
Google App Engine memcache 
Redis Cache 
Maintaining consistency between 
data in cache & data in 
underlying data store 


Cache-Aside Pattern (Cont.) 
 
Parameters 
 
 
 
 
What to cache 
Lifetime of cached data 
Cache size 
Evicting data In Memory 
Caching 
Read/write performance 
When


Competing Consumers Pattern 
Multiple concurrent consumers to process messages 
received on same channel 
Goals 
Optimize throughput, improve scalability & availability, load 
balancing 


Competing Consumers Pattern (Cont.) 
When 
 
 
Independent tasks that can be processed parallel 
Volume of work is highly variable 
High availability 


Competing Consumers Pattern (Cont.) 
Parameters 
 
 
 
 
 
 
Queue size 
Scaling 
Not loosing messages 
Preserving message ordering 
Resiliency 
Poison/malformed messages 
Returning results 


Queue-Based Load Leveling Pattern 
To smooth intermittent heavy loads that may otherwise 
cause the service to fail or the task to time out 


Queue-Based Load Leveling 
Pattern 


Priority Queue Pattern 
Prioritize requests sent to services so that requests with 
a higher priority are received & processed quickly 


Priority Queue Pattern 
(Cont.) 


Priority Queue Pattern (Cont.) 
When, 
The system handles multiple tasks that have different 
priorities 
Different users should be served with different 
priorities 


Pipes & Filters Pattern 


Pipes & Filters Pattern (Cont.) 
Decompose a task that performs complex processing 
into a series of discrete elements that can be reused 


Pipes & Filters Pattern ‚Äì With 
Load Balancing 
When, 
 
 
 
Application can be decomposed to steps 
Steps have different scalability requirements 
Flexibility of processing 
Need distributed processing 




Load Balancing
Aims to 
 Improves the distribution of workloads across 
multiple computing resources 
 
 
 
Optimize resource use 
Maximize throughput 
Minimize response time 
Avoid overload of any single resource 
Some resources will be busy while others are idle 


Load Balancing 
Counter by distributing load equally 
2 methods for dynamic load balancing 
Some other problems are not that simple 
When cost of problem is well understood (e.g., matrix 
multiplication, known tree walk) this is possible 
- Hard to predict how workload will be distributed 
- dynamic load balancing used 
 - But require communication between tasks 
Task queues vs. work stealing 


Task Queues 
Multiple instance of task queues (producer 
consumer) 
Threads comes to the task queue after finishing a 
task & grab next task 
Typically run with a pool of workers 
Source: http://blog.zenika.com 


Work Stealing 
 Every worker has a task queue 
When 1 worker runs out of work, it goes to other 
worker‚Äôs queue & ‚Äústeal‚Äù the work 
Source: http://karlsenchoi.blogspot.com 


Sharding Pattern 
Divide a data store into a set of horizontal partitions or 
shards to improve scalability 


Sharding Pattern (Cont) 
 When 
Sharding Strategies 
 
 
 
 
Limited storage space 
Large computation requirement 
Network bandwidth 
Geographical constraints 
Lookup Strategy ‚Äì map request using a shard key 
Range Strategy ‚Äì groups related items together in the same 
shard 
Hash Strategy ‚Äì shard decided based on hashing data attributes 


Valet Key Pattern 
Use a token or key that provides client with restricted 
direct access to a specific resource or service 


Gatekeeper Pattern 
Protect applications & services using a 
dedicated host instance that acts as a broker 
 Validates & sanitizes requests 
Passes requests & data between them 


Gatekeeper Pattern (Cont.) 
 
 
Only function is to validate & sanitize requests 
Should use secure communication between 
gatekeeper & trusted hosts 
  Internal end point must connect only to 
gatekeeper 
Gatekeeper must run in limited privilege mode 
May use multiple gatekeepers for availability 


Circuit Breaker Pattern 


Circuit Breaker Pattern (Cont.) 
When 
Half-Open State 
 
Allow checking whether service is responding by 
issuing a limited set of requests 
Prevent repeated system failures due to rapid 
load/volume 
Handle faults that may take a variable amount of time 
to rectify when connecting to a remote 
service/resource 
When a simple retry will not work 
Prevent application from getting tied-up due to retry 


Circuit Breaker Pattern (Cont.) 
Parameters 
 
 
 
 
Types of exceptions 
Handling exceptions 
Logging & replay 
Testing failed operations 
Manual reset 


Compensating Transaction Pattern 


Compensating Transaction Pattern 
(Cont.) 
 Undo work performed by a series of steps, which 
together define an eventually consistent 
operation 
 Implement a workflow 
As operation proceeds, system records information 
about each step & how the work by that step can be 
undone 
If operation fails at any point, workflow rewinds 
back through steps it has completed while performing 
work that reverses each step 


Event Sourcing Pattern 


Event Sourcing Pattern (Cont.) 
 
Cons 
Record full series of events than current state 
Pros 
 
 
 
Consistency relaxed 
Avoid requirement to synchronize data 
Scalability 
Responsiveness 
Provide consistency for transactional data 
Full audit trails 
Traditional Create, Read, Update, & Delete (CRUD) model 
too slow 
Improve performance with eventual consistency 


External Configuration Store Pattern 
Move configuration information out of application 
deployment package to a central location 


Federated Identity Pattern 
Delegate authentication to an external identity provider 


Health Endpoint Monitoring Pattern 
Functional checks within an application that external tools 
can access through exposed endpoints at regular intervals


Throttling Pattern 
 Control consumption of resources used by an instance 
Allow system to continue to function & meet SLA even 
when an increase in demand places an extreme load on resources 
21 


Introduction to
Machine Learning
By Jeewaka Perera


Lesson 
Objectives
‚Ä¢ At the end of the lesson students 
should be able to explain
‚Ä¢ What is Machine Learning?
‚Ä¢ Why Choose Machine Learning?
‚Ä¢ Different Machine Learning 
Algorithms and their applications


What is Optimization?
‚Ä¢ Optimization is the mathematical 
discipline which is concerned 
with finding the maxima and 
minima of functions, possibly 
subject to constraints.


What is
Artificial 
Intelligence
‚Ä¢ " It is the science and
engineering of making intelligent 
machines, especially intelligent 
computer programs. It is related 
to the similar task of using 
computers to understand human 
intelligence, but AI does not have 
to confine itself to methods that 
are biologically observable.‚Äú by 
John McCarthy


What is Machine
Learning
‚Ä¢ ‚Äúfield of study that gives computers the ability to learn 
without explicitly being programmed.‚Äù by Arthur Samuel
‚Ä¢ Machine learning is a subfield of artificial intelligence, 
which is broadly defined as the capability of a machine to 
imitate intelligent human behavior.


Learning in a 
Machine
‚Ä¢ ‚ÄúA computer program is said to learn 
from experience (E) with some class of 
tasks (T) and a performance measure (P) 
if its performance at tasks in T as
measured by P improves with E‚Äù
2
9
7


Computer
Output
Computer
Data 
Program
Output
Data
Program
ML vs Traditional programming
Traditional Programming
Machine Learning
Learning Algorithm
2
9
8


Types of
Artificial 
Intelligence 
Algorithms
Rule-based expert 
Systems
Search Algorithms
Evolutionary Algorithms and Swam
Intelligence Algorithms
Machine Learning Algorithms


Rule Based 
Systems
‚Ä¢ Expert Systems
‚Ä¢
PROSPECTOR
‚Ä¢
MYCIN
‚Ä¢ Based on pre-defined Rules
‚Ä¢ Rules defined based on domain knowledge
‚Ä¢ Designed to mimic the decision-making 
process of human experts


Search
Algorithms
‚Ä¢ Breadth-First Search
‚Ä¢ Depth First Search
‚Ä¢ Iterative Deepening Search
‚Ä¢ Uniform Cost Search
‚Ä¢
Dijkstra's algorithm
‚Ä¢ A* Search
Sample Footer Text
30
1


Evolutionary
Algorithms
‚Ä¢ Evolutionary Algorithms are a family of nature-inspired 
optimization algorithms that mimic biological evolution‚Äî
natural selection, mutation, recombination, and survival of 
the fittest.
‚Ä¢
Genetic Algorithms
‚Ä¢
Particle Swarm Optimization
‚Ä¢
Cultural Algorithms
‚Ä¢
HCA KCA
‚Ä¢
SI Algorithms(ACO, FA)
Sample Footer Text
30
2


Steps in a generic Evolutionary Algorithm
Initialize a population 
of potential solutions 
randomly.
Evaluate each solution 
using a fitness 
function.
Select the best 
individuals.
Recombine (crossover) 
and mutate them to 
create new individuals.
Repeat until a stopping 
condition is met.


Applications of EA
SCHEDULING AIRLINE 
CREWS
TUNING 
HYPERPARAMETERS IN ML
DESIGNING ANTENNAS 
(NASA EXAMPLE!)
PORTFOLIO 
OPTIMIZATION


Genetic Algorithms
‚Ä¢
A Genetic Algorithm (GA) is a search and 
optimization method inspired by how living 
things evolve over time through natural 
selection. 
‚Ä¢
We represent potential solutions as 
chromosomes.
‚Ä¢
Better solutions (those with higher fitness) are 
selected
‚Ä¢
New solutions are created through crossover 
and mutation
‚Ä¢
Over generations, solutions get better!


Swarm Intelligence 
Algorithms
‚Ä¢ Inspired by: Collective behavior of decentralized, self-
organized systems (e.g., birds, ants, fish)
‚Ä¢ Ant Colony Optimization (ACO)
‚Ä¢ Inspired by ants finding shortest paths using 
pheromone trails.
‚Ä¢ Good for discrete path-based problems like the 
Traveling Salesman Problem (TSP).
‚Ä¢ Firefly Algorithm (FA)
‚Ä¢ Fireflies are attracted to brighter (better) solutions.
‚Ä¢ Uses light intensity and distance for movement.


Types of Machine Learning Algorithms
12
SUPERVISED LEARNING
UNSUPERVISED 
LEARNING
SEMI-SUPERVISED 
LEARNING
REINFORCEMENT 
LEARNING


Supervised Learning
Algorithms
‚Ä¢ Learned under supervision.
‚Ä¢ Supervision of what?
‚Ä¢ Humans?
‚Ä¢ Supervised by the Labeled data
‚Ä¢ Require labeled data. (Inputs, output)
‚Ä¢ This is the most difficult part of supervised learning.
Tuesday, February 2, 20XX
Sample Footer Text
13


Types of Supervised Learning
Models
‚Ä¢ Regression
‚Ä¢ Predicting a Linear 
value
‚Ä¢ Linear Regression
‚Ä¢ SVR
‚Ä¢ DT
‚Ä¢ Classification
‚Ä¢ Predicting a 
class/label
‚Ä¢ Logistic Regression
‚Ä¢ SVM
‚Ä¢ DT
‚Ä¢ NB
14
Artificial Neural Network Models such as MLP, CNN, RNNs are 
Considered as supervised Learning Models


Supervised 
learning 
examples
310
A Bank may have borrower details (age, 
income, gender, etc.) of the past (features)
Also it may have details of the borrowers who 
defaulted in the past (labels)
Based on the above, can train a classifier to 
learn the patterns of borrowers who are likely 
to default on their payments


Linear 
Regression
‚Ä¢ Model Explanation:
 
Draws a straight line that best fits the data.
‚Ä¢ Key Concept:
 
Learns the relationship as a linear equation: 
‚Ä¢ y = mx + c.
‚Ä¢ What is learnt through training:
 
Finds the best slope (m) and intercept (c) to 
minimize error.
‚Ä¢ Example Use Cases:
‚Ä¢ Predicting house prices
‚Ä¢ Salary estimation
‚Ä¢ Sales forecasting
‚Ä¢ Limitations:
‚Ä¢ Only works well when the relationship is linear
‚Ä¢ Not suitable for complex, non-linear patterns
‚Ä¢ Sensitive to outliers


Linear 
regression
‚ÄúPredictor‚Äù:
Evaluate line:
return r
31
2


Types of
Unsupervised 
Learning
Algorithms
‚Ä¢ Clustering Algorithms
‚Ä¢ K Means
‚Ä¢ DBSCAN
‚Ä¢ Dimensionality Reduction Algorithms
‚Ä¢ PCA
‚Ä¢ MDS (Multidimensional Scaling)
‚Ä¢ LDA (Linear Discriminant Analysis)
‚Ä¢ Graph Based Models can be considered as Unsupervised 
Learning
Sample Footer Text
31
3


Unsupervised learning examples
314
A Supermarket may store each buyer‚Äôs
basket content details (features)
There are NO grouping (labels)
Need to group the buyers based on their 
buying patterns 
in order to best use the shelf space (recommendation)


K- Means 
Clustering
‚Ä¢
Model Explanation:
‚Ä¢
Groups data into K clusters based on similarity.
‚Ä¢
Key Concept:
‚Ä¢
Finds cluster centers and assigns each point to the nearest 
one.
‚Ä¢
What is learnt through training:
‚Ä¢
Learns the position of cluster centers.
‚Ä¢
Example Use Cases:
‚Ä¢
Customer segmentation
‚Ä¢
Grouping articles by topic
‚Ä¢
Organizing images
‚Ä¢
Limitations:
‚Ä¢
You must choose K (number of clusters) beforehand
‚Ä¢
Assumes spherical-shaped clusters
‚Ä¢
Struggles with uneven or noisy data


K-means clustering example
31
6


DBSCAN
‚Ä¢
Model Explanation:
‚Ä¢
Groups together dense areas; labels sparse points as outliers.
‚Ä¢
Key Concept:
‚Ä¢
Clusters are formed based on density, not shape or number.
‚Ä¢
What is learnt through training:
‚Ä¢
Learns which points belong to dense clusters and which are 
noise.
‚Ä¢
Example Use Cases:
‚Ä¢
Fraud detection
‚Ä¢
Identifying event hotspots
‚Ä¢
Anomaly detection in GPS or sensor data
‚Ä¢
Limitations:
‚Ä¢
Struggles with varying densities
‚Ä¢
Requires tuning of eps and min points
‚Ä¢
Not ideal for high-dimensional data






Semi-supervised learning
320
Labeled data is expensive/difficult to get
Unlabeled data is cheap/easier to get
The idea is to use smaller amount of labelled 
data with larger 
amount of unlabeled data to 
creating the training/testing datasets
Algorithms - Self Training, Generative models
‚Ä¢ Semi-Supervised Support Vector Machines, etc.


Semi-Supervised
Learning 
Algorithms
‚Ä¢ Generative Adversarial Networks
‚Ä¢ Auto-encoders
‚Ä¢ Variational Auto-encoders
Sample Footer Text
32
1


Ensemble
Learning
‚Ä¢ Often, multiple classifiers need to be combined to 
solve a real-world problem.
32
2


Random 
Forest
‚Ä¢
Model Explanation:
‚Ä¢
Combines predictions from many decision trees.
‚Ä¢
Key Concept:
‚Ä¢
Uses voting or averaging to make decisions.
‚Ä¢
What is learnt through training:
‚Ä¢
Learns different rules from subsets of data to make robust 
predictions.
‚Ä¢
Example Use Cases:
‚Ä¢
Spam detection
‚Ä¢
Credit risk analysis
‚Ä¢
Disease classification
‚Ä¢
Limitations:
‚Ä¢
Can be slow with large datasets
‚Ä¢
Less interpretable than a single decision tree
‚Ä¢
Needs tuning (like number of trees)




Reinforcement 
Learning
‚Ä¢
Model Explanation:
‚Ä¢
Learns by interacting with an environment and 
receiving feedback (rewards or penalties).
‚Ä¢
Key Concept:
‚Ä¢
Uses trial-and-error and reward maximization 
to improve decision-making over time.
‚Ä¢
What is learnt through training:
‚Ä¢
Learns an optimal policy or action strategy that 
maximizes long-term rewards.
‚Ä¢
Example Use Cases:
‚Ä¢
Game playing (e.g., AlphaGo)
‚Ä¢
Robotics (e.g., navigation or motor control)
‚Ä¢
Dynamic pricing or recommendation systems
‚Ä¢
Limitations:
‚Ä¢
Requires many interactions with the 
environment (sample inefficiency)
‚Ä¢
Can be unstable or hard to converge
‚Ä¢
Needs careful reward design to avoid 
unintended behaviors


Reinforcement learning 
examples
24
A group of robots have been deployed in an unknown 
territory
The objective is for them to collaboratively find the 
navigation path to reach a particular destination/goal
Can use reinforcement learning where achieving the 
goal/getting closer to the goal gives a positive reward. 
Negative reward otherwise
Can share the information among robots (multi-agent 
system)


Comparing 
Machine 
Learning 
Models
Key Questions to Ask:
Is it a 
classification, 
regression, or 
clustering task?
Do we care more 
about correctness, 
fairness, or 
interpretability?
What are the costs 
of wrong 
predictions?
Not all models are created 
equal ‚Äî and neither are the 
ways we evaluate them.


Common Evaluation Matrices
Task Type
Metrics Used
Classification
Accuracy, Precision, Recall, F1 Score, ROC-AUC
Regression
MSE, MAE, RMSE, R¬≤ Score
Clustering
Silhouette Score, Davies-Bouldin Index, Inertia
Ranking/Recommendation
MAP, NDCG, Hit Rate


Classification Matrices Explained
Metric
Use When...
Notes
Accuracy
Classes are balanced, all errors 
matter
Can be misleading with imbalance
Precision
False positives are costly (e.g., 
spam)
TP / (TP + FP)
Recall
False negatives are costly (e.g., 
cancer)
TP / (TP + FN)
F1 Score
Balance between precision and 
recall
Harmonic mean
ROC-AUC
Need to evaluate ranking ability
Works for probabilistic models


Regression Model
Metric
Use When...
Notes
MSE
Large errors are very bad
Penalizes large errors more
MAE
Equal penalty for all errors
More robust to outliers
RMSE
Like MSE but in original units
Square root of MSE
R¬≤ Score
Want to explain variability in 
output
1 = perfect, 0 = no 


Clustering Algorithms
Metric
Use When...
Notes
Silhouette Score
Want to measure how 
distinct clusters are
1 = well-clustered, -1 = 
wrong
Davies-Bouldin Index
Lower is better (compact 
& separated)
Good for comparing k-
values
Inertia (within-cluster 
SSE)
Used in K-Means
Lower is better, but not 
scaled


Practical Evaluation Factors
Factor
Why It Matters
Interpretability
Do we understand how/why it makes predictions?
Training Time
Important for real-time or big data
Fairness
Does it treat all groups equally?
Generalization
Does it perform well on new data?
Explainability
Can we explain decisions to stakeholders?


33
3
Things to consider in Selecting a
ML Algorithm
‚Ä¢ If there‚Äôs an algorithmic way instead of ML, use it!!! (ML is
‚Ä¢ messy)
‚Ä¢ Refer the literature!!!
‚Ä¢ Try different ML algorithms (no single algorithm is the best)
‚Ä¢ Check the dataset against the usage/strength of each algorithm (e.g.
RNNs, ARIMA is good in time-series predictions)
‚Ä¢ Be mindful of ‚Äòexternal factors‚Äô (e.g. seasonal effects, RL if you
‚Ä¢ don‚Äôt have data, Clustering if you have unlabeled data, etc.)
‚Ä¢ Test your algorithm(s) with test data and select the best 
performing
one for production (include the test results in your 
thesis/publications)
‚Ä¢ No algorithm will be perfect! (There will be an error. The 
objective is to keep the error at an acceptable rate)


33
4
Popular Frameworks/Tools
‚Ä¢ Scikit-learn - Python (Anaconda Python Distribution)
‚Ä¢ R (R studio)
‚Ä¢ Matlab/Octave (can export DLLs)
‚Ä¢ Weka (Java based)
‚Ä¢ Java OpenNLP/Python NLTK (Natural language processing
+ ML)
‚Ä¢ Apache Spark (part of the Apache Hadoop platform)
‚Ä¢ Google Tensorflow (Python library for Deep neural 
networks)
‚Ä¢ Apache Keras (Python library of neural networks)
‚Ä¢ Theano (Python library for Multicore processing of DNNs)
‚Ä¢ Amazon AWS Services/Microsoft Azure ML (Cloud based 
ML)


Commonly 
used 
python 
libraries
335
NumPy
Matrix algebra
Pandas
Data Frames, Series
Matpotlib
Visualization


Summary
‚Ä¢ AI is a vast discipline with many 
varying branches.
‚Ä¢ AI attempts to give machine the 
ability to mimic human decision 
making/learning capabilities
Tuesday, February 2, 20XX
Sample Footer Text
33
6


Thank You
Jeewaka Perera
Jeewaka.p@sliit.lk
Tuesday, February 2, 20XX
Sample Footer Text
33
7


